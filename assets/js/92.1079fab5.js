(window.webpackJsonp=window.webpackJsonp||[]).push([[92],{715:function(t,s,e){"use strict";e.r(s);var a=e(5),n=Object(a.a)({},(function(){var t=this,s=t.$createElement,e=t._self._c||s;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("div",{staticClass:"custom-block tip"},[e("p",{staticClass:"custom-block-title"},[t._v("ËØ¥Êòé")]),t._v(" "),e("p",[t._v("‚Äã\tÊú¨Êñá‰∏ªË¶Å‰ªãÁªçWhisperÁöÑÂü∫Êú¨‰ΩøÁî®ÔºåÂÆûÁé∞ËØ≠Èü≥ÁöÑËæìÂÖ•ËæìÂá∫")]),t._v(" "),e("p",[e("a",{attrs:{href:"www.deep-diary.com"}},[t._v("ÁÇπÂáªÂÖçË¥πËßÇÁúãÊïôÂ≠¶ËßÜÈ¢ë")])])]),t._v(" "),e("h1",{attrs:{id:"audio-transformers"}},[t._v("Audio Transformers")]),t._v(" "),e("h2",{attrs:{id:"ÁÆÄÂçï‰ΩøÁî®"}},[t._v("ÁÆÄÂçï‰ΩøÁî®")]),t._v(" "),e("div",{staticClass:"language-python line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" torch\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" transformers "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pipeline\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" datasets "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" load_dataset"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Audio\n\n\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("AudioTransformers")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("__init__")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("pass")]),t._v("\n\n    "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("on_speech_recognizer")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" dataset"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        speech_recognizer "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pipeline"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"automatic-speech-recognition"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"facebook/wav2vec2-base-960h"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        result "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" speech_recognizer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" result\n\n\ndataset "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" load_dataset"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"PolyAI/minds14"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" name"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"en-US"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" split"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"train"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# dataset = dataset.cast_column("audio", Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))')]),t._v("\n\n\naudio_transformers "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" AudioTransformers"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nresult "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" audio_transformers"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("on_speech_recognizer"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dataset"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"audio"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("d"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"text"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" d "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" result"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br"),e("span",{staticClass:"line-number"},[t._v("3")]),e("br"),e("span",{staticClass:"line-number"},[t._v("4")]),e("br"),e("span",{staticClass:"line-number"},[t._v("5")]),e("br"),e("span",{staticClass:"line-number"},[t._v("6")]),e("br"),e("span",{staticClass:"line-number"},[t._v("7")]),e("br"),e("span",{staticClass:"line-number"},[t._v("8")]),e("br"),e("span",{staticClass:"line-number"},[t._v("9")]),e("br"),e("span",{staticClass:"line-number"},[t._v("10")]),e("br"),e("span",{staticClass:"line-number"},[t._v("11")]),e("br"),e("span",{staticClass:"line-number"},[t._v("12")]),e("br"),e("span",{staticClass:"line-number"},[t._v("13")]),e("br"),e("span",{staticClass:"line-number"},[t._v("14")]),e("br"),e("span",{staticClass:"line-number"},[t._v("15")]),e("br"),e("span",{staticClass:"line-number"},[t._v("16")]),e("br"),e("span",{staticClass:"line-number"},[t._v("17")]),e("br"),e("span",{staticClass:"line-number"},[t._v("18")]),e("br"),e("span",{staticClass:"line-number"},[t._v("19")]),e("br"),e("span",{staticClass:"line-number"},[t._v("20")]),e("br"),e("span",{staticClass:"line-number"},[t._v("21")]),e("br"),e("span",{staticClass:"line-number"},[t._v("22")]),e("br"),e("span",{staticClass:"line-number"},[t._v("23")]),e("br")])]),e("p",[t._v("Âá∫Áé∞Êä•ÈîôÔºåÂ∫îËØ•Â∞±ÊòØÁº∫Â∞ë2‰∏™Â∫ì")]),t._v(" "),e("div",{staticClass:"language-shell line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[t._v("Dataset minds14 downloaded and prepared to C:/Users/Blue/.cache/huggingface/datasets/PolyAI___minds14/en-US/1.0.0/65c7e0f3be79e18a6ffaf879a083daf706312d421ac90d25718459cbf3c42696. Subsequent calls will reuse this data.\n  File "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D:\\BlueDoc\\DiaryWin'),e("span",{pre:!0,attrs:{class:"token entity",title:"\\v"}},[t._v("\\v")]),t._v("env\\lib\\site-packages\\datasets"),e("span",{pre:!0,attrs:{class:"token entity",title:"\\f"}},[t._v("\\f")]),t._v("eatures"),e("span",{pre:!0,attrs:{class:"token entity",title:"\\a"}},[t._v("\\a")]),t._v('udio.py"')]),t._v(", line "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("155")]),t._v(", "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" decode_example\n    "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("import")]),t._v(" librosa\nModuleNotFoundError: No module named "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'librosa'")]),t._v("\nThe above exception was the direct cause of the following exception:\nTraceback "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("most recent call last"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(":\n  File "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"D:\\BlueDoc\\DiaryWin'),e("span",{pre:!0,attrs:{class:"token entity",title:"\\v"}},[t._v("\\v")]),t._v("env\\lib\\site-packages\\datasets"),e("span",{pre:!0,attrs:{class:"token entity",title:"\\f"}},[t._v("\\f")]),t._v("eatures"),e("span",{pre:!0,attrs:{class:"token entity",title:"\\a"}},[t._v("\\a")]),t._v('udio.py"')]),t._v(", line "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("158")]),t._v(", "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" decode_example\n    raise ImportError"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"To support decoding audio files, please install 'librosa' and 'soundfile'.\"")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" from err\nImportError: To support decoding audio files, please "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'librosa'")]),t._v(" and "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v("'soundfile'")]),e("span",{pre:!0,attrs:{class:"token builtin class-name"}},[t._v(".")]),t._v("\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br"),e("span",{staticClass:"line-number"},[t._v("3")]),e("br"),e("span",{staticClass:"line-number"},[t._v("4")]),e("br"),e("span",{staticClass:"line-number"},[t._v("5")]),e("br"),e("span",{staticClass:"line-number"},[t._v("6")]),e("br"),e("span",{staticClass:"line-number"},[t._v("7")]),e("br"),e("span",{staticClass:"line-number"},[t._v("8")]),e("br"),e("span",{staticClass:"line-number"},[t._v("9")]),e("br")])]),e("p",[t._v("Êé™ÊñΩ")]),t._v(" "),e("div",{staticClass:"language-shell line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-shell"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("venv"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" PS D:"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("BlueDoc"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("\\")]),t._v("DiaryWin"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" pip "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" librosa soundfile\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br")])]),e("p",[t._v("ÂÆâË£ÖÂ•Ω‰∏äËø∞2‰∏™Â∫ìÂêéÔºåÂç≥ÂèØËß£ÂÜ≥Êä•Èîô")]),t._v(" "),e("h2",{attrs:{id:"pipelines-ÂèÇÊï∞Ëß£Êûê"}},[t._v("pipelines ÂèÇÊï∞Ëß£Êûê")]),t._v(" "),e("h3",{attrs:{id:"device"}},[t._v("Device")]),t._v(" "),e("p",[t._v("If you use "),e("code",[t._v("device=n")]),t._v(", the pipeline automatically puts the model on the specified device. This will work regardless of whether you are using PyTorch or Tensorflow.")]),t._v(" "),e("div",{staticClass:"language-python line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[t._v("generator "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pipeline"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("model"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"openai/whisper-large"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" device"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br")])]),e("p",[t._v("If the model is too large for a single GPU, you can set "),e("code",[t._v('device_map="auto"')]),t._v(" to allow ü§ó "),e("a",{attrs:{href:"https://huggingface.co/docs/accelerate",target:"_blank",rel:"noopener noreferrer"}},[t._v("Accelerate"),e("OutboundLink")],1),t._v(" to automatically determine how to load and store the model weights.")]),t._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v('#!pip install accelerate\ngenerator = pipeline(model="openai/whisper-large", device_map="auto", batch_size=2)\n')])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br")])]),e("p",[t._v("Note that if "),e("code",[t._v('device_map="auto"')]),t._v(" is passed, there is no need to add the argument "),e("code",[t._v("device=device")]),t._v(" when instantiating your "),e("code",[t._v("pipeline")]),t._v(" as you may encounter some unexpected behavior!")]),t._v(" "),e("h3",{attrs:{id:"batch-size"}},[t._v("Batch size")]),t._v(" "),e("p",[t._v("By default, pipelines will not batch inference for reasons explained in detail "),e("a",{attrs:{href:"https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-batching",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),e("OutboundLink")],1),t._v(". The reason is that batching is not necessarily faster, and can actually be quite slower in some cases.")]),t._v(" "),e("p",[t._v("But if it works in your use case, you can use:")]),t._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v('generator = pipeline(model="openai/whisper-large", device=0, batch_size=2)\naudio_filenames = [f"audio_{i}.flac" for i in range(10)]\ntexts = generator(audio_filenames)\n')])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br"),e("span",{staticClass:"line-number"},[t._v("3")]),e("br")])]),e("p",[t._v("This runs the pipeline on the 10 provided audio files, but it will pass them in batches of 2 to the model (which is on a GPU, where batching is more likely to help) without requiring any further code from you. The output should always match what you would have received without batching. It is only meant as a way to help you get more speed out of a pipeline.")]),t._v(" "),e("p",[t._v("Pipelines can also alleviate some of the complexities of batching because, for some pipelines, a single item (like a long audio file) needs to be chunked into multiple parts to be processed by a model. The pipeline performs this "),e("a",{attrs:{href:"https://huggingface.co/docs/transformers/main_classes/pipelines#pipeline-chunk-batching",target:"_blank",rel:"noopener noreferrer"}},[e("em",[t._v("chunk batching")]),e("OutboundLink")],1),t._v(" for you.")]),t._v(" "),e("h3",{attrs:{id:"task-specific-parameters"}},[t._v("Task specific parameters")]),t._v(" "),e("p",[t._v("All tasks provide task specific parameters which allow for additional flexibility and options to help you get your job done. For instance, the "),e("a",{attrs:{href:"https://huggingface.co/docs/transformers/v4.30.0/en/main_classes/pipelines#transformers.AutomaticSpeechRecognitionPipeline.__call__",target:"_blank",rel:"noopener noreferrer"}},[t._v("transformers.AutomaticSpeechRecognitionPipeline."),e("strong",[t._v("call")]),t._v("()"),e("OutboundLink")],1),t._v(" method has a "),e("code",[t._v("return_timestamps")]),t._v(" parameter which sounds promising for subtitling videos:")]),t._v(" "),e("div",{staticClass:"language- line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v(">>> # Not using whisper, as it cannot provide timestamps.\n>>> generator = pipeline(model=\"facebook/wav2vec2-large-960h-lv60-self\", return_timestamps=\"word\")\n>>> generator(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP AND LIVE OUT THE TRUE MEANING OF ITS CREED', 'chunks': [{'text': 'I', 'timestamp': (1.22, 1.24)}, {'text': 'HAVE', 'timestamp': (1.42, 1.58)}, {'text': 'A', 'timestamp': (1.66, 1.68)}, {'text': 'DREAM', 'timestamp': (1.76, 2.14)}, {'text': 'BUT', 'timestamp': (3.68, 3.8)}, {'text': 'ONE', 'timestamp': (3.94, 4.06)}, {'text': 'DAY', 'timestamp': (4.16, 4.3)}, {'text': 'THIS', 'timestamp': (6.36, 6.54)}, {'text': 'NATION', 'timestamp': (6.68, 7.1)}, {'text': 'WILL', 'timestamp': (7.32, 7.56)}, {'text': 'RISE', 'timestamp': (7.8, 8.26)}, {'text': 'UP', 'timestamp': (8.38, 8.48)}, {'text': 'AND', 'timestamp': (10.08, 10.18)}, {'text': 'LIVE', 'timestamp': (10.26, 10.48)}, {'text': 'OUT', 'timestamp': (10.58, 10.7)}, {'text': 'THE', 'timestamp': (10.82, 10.9)}, {'text': 'TRUE', 'timestamp': (10.98, 11.18)}, {'text': 'MEANING', 'timestamp': (11.26, 11.58)}, {'text': 'OF', 'timestamp': (11.66, 11.7)}, {'text': 'ITS', 'timestamp': (11.76, 11.88)}, {'text': 'CREED', 'timestamp': (12.0, 12.38)}]}\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br"),e("span",{staticClass:"line-number"},[t._v("3")]),e("br"),e("span",{staticClass:"line-number"},[t._v("4")]),e("br")])]),e("p",[t._v("As you can see, the model inferred the text and also outputted "),e("strong",[t._v("when")]),t._v(" the various words were pronounced in the sentence.")]),t._v(" "),e("h2",{attrs:{id:"ËØ¥ËØùÊÉÖÁª™ËØÜÂà´"}},[t._v("ËØ¥ËØùÊÉÖÁª™ËØÜÂà´")]),t._v(" "),e("div",{staticClass:"language-python line-numbers-mode"},[e("pre",{pre:!0,attrs:{class:"language-python"}},[e("code",[e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" transformers "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pipeline\n\nclassifier "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pipeline"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("task"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"audio-classification"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" model"),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"superb/hubert-base-superb-er"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npreds "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" classifier"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\npreds "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"score"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("round")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("pred"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"score"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token number"}},[t._v("4")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"label"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" pred"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"label"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" pred "),e("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" preds"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\npreds\n")])]),t._v(" "),e("div",{staticClass:"line-numbers-wrapper"},[e("span",{staticClass:"line-number"},[t._v("1")]),e("br"),e("span",{staticClass:"line-number"},[t._v("2")]),e("br"),e("span",{staticClass:"line-number"},[t._v("3")]),e("br"),e("span",{staticClass:"line-number"},[t._v("4")]),e("br"),e("span",{staticClass:"line-number"},[t._v("5")]),e("br"),e("span",{staticClass:"line-number"},[t._v("6")]),e("br")])]),e("h2",{attrs:{id:"Êõ¥Êñ∞ËÆ∞ÂΩï"}},[t._v("Êõ¥Êñ∞ËÆ∞ÂΩï")]),t._v(" "),e("table",[e("thead",[e("tr",[e("th",[t._v("Date")]),t._v(" "),e("th",[t._v("Updated Info")]),t._v(" "),e("th",[t._v("Address")])])]),t._v(" "),e("tbody",[e("tr",[e("td",[t._v("2023-06-17")]),t._v(" "),e("td",[t._v("init")]),t._v(" "),e("td",[t._v("@ home")])]),t._v(" "),e("tr",[e("td"),t._v(" "),e("td"),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td"),t._v(" "),e("td"),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td"),t._v(" "),e("td"),t._v(" "),e("td")]),t._v(" "),e("tr",[e("td"),t._v(" "),e("td"),t._v(" "),e("td")])])])])}),[],!1,null,null,null);s.default=n.exports}}]);